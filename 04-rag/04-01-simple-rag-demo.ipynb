{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install qdrant-client\n",
    "%pip install openai\n",
    "%pip install sentence-transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all-MiniLM-L6-v2\n",
    "\n",
    "- **Architecture**: A lightweight and efficient version of Microsoft's larger models, based on the Transformer architecture with 6 layers.\n",
    "- **Purpose**: Designed for natural language understanding and generation, optimized for performance on edge devices.\n",
    "- **Language Coverage**: Supports multiple languages, suitable for international applications.\n",
    "- **Usage**: Ideal for scenarios where model size and processing speed are crucial, such as mobile devices or web applications.\n",
    "- **Performance**: Offers a good balance between performance and efficiency, despite its smaller size.\n",
    "- **Quality of Embeddings**: Generates high-quality, dense text representations, efficiently capturing semantic meanings.\n",
    "- **Dimensionality**: Produces embeddings with lower dimensionality, reducing computational requirements while maintaining effectiveness.\n",
    "- **Similarity and Clustering Tasks**: Useful for semantic similarity measurements, document clustering, and information retrieval systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stmodel = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "azure_api_key = os.environ.get(\"AZURE_OPENAI_KEY\")\n",
    "azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI API\n",
    "model = \"gpt-35-turbo\"\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=\"2024-02-15-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API\n",
    "model = \"gpt-3.5-turbo\"\n",
    "openai_client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(host='localhost', port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(collection_name=\"hockey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"hockey\",\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.DOT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Automatic Game Misconduct – An automatic game misconduct shall be applied to any player who has been assessed a third major penalty, or second fighting major penalty, in the same game. The automatic game misconduct penalty due to the third major penalty, or second fighting major penalty, shall be waived for a player in the altercation if the opposing player was assessed an instigator penalty in either altercation.\",\n",
    "    \"Match Penalty – A match penalty involves the suspension of a player for the balance of the game and the offender shall be ordered to the dressing room immediately.\",\n",
    "    \"Game Misconduct Penalty – A game misconduct penalty involves th suspension of a player for the balance of the game but a substitute is permitted to replace the player removed. Ten minutes are applied in the league records to the player incurring a game misconduct.\",\n",
    "    \"In regular League games, any player who incurs a total of ten (10) fighting major penalties shall be suspended automatically for the next League game of his team. For each subsequent fighting major penalty the player shall be suspended automatically for the next League game of his team.\",\n",
    "    \"In regular League games, any player who incurs a total of fourteen (14) fighting major penalties shall then be suspended automatically for the next two (2) League games of his team. For each subsequent fighting major penalty the player shall be suspended automatically for the next two (2) League games of his team.\" ,\n",
    "    \"In addition, the following list of infractions can also result in a game misconduct penalty being assessed: (i) interfering with or striking a spectator (ii) racial taunts or slur (iii) spitting on or at an opponent or spectator\",\n",
    "    \"Boarding - A boarding penalty shall be imposed on any player who checks or pushes a defenseless opponent in such a manner that causes the opponent to hit or impact in the boards violently or dangerously. The everity of the penalty, based upon the impact with the boards, shall be at the discretion of the Referee.\"\n",
    "]\n",
    "metadata = [f\"AHL Rulebook\" for i in range(len(documents))]\n",
    "ids = [i for i in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = stmodel.encode(documents) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = [\"AHL Rulebook\" for _ in range(len(documents))]\n",
    "ids = list(range(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [\n",
    "    PointStruct(id=id_, vector=vector.tolist(), payload={\"text\": doc, \"metadata\": meta})\n",
    "    for id_, vector, doc, meta in zip(ids, vectors, documents, metadata)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_info = client.upsert(\n",
    "    collection_name=\"hockey\",\n",
    "    wait=True,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is a game misconduct penalty?\"\n",
    "query_vector = stmodel.encode([query])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = client.search(\n",
    "    collection_name=\"hockey\", query_vector=query_vector, limit=3\n",
    ")\n",
    "\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for s in search_result:\n",
    "    print(s)\n",
    "    results.append(s.payload[\"text\"])\n",
    "\n",
    "# turn results into a string\n",
    "results = \"\\n\".join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an expert in hockey rules.  Use the references from the AHL Rulebook to answer the question.\"\n",
    "prompt = f\"\"\"Use the QUERY below, along with the CONTEXT to answer the query.  Do not use any other sources to answer the question.  If you do not know the answer, answer 'I don't know.\n",
    "\n",
    "== QUERY ==\n",
    "{query}\n",
    "== END QUERY ==\n",
    "\n",
    "== CONTEXT ==\n",
    "{results}\n",
    "== END CONTEXT ==\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    { \"role\": \"system\", \"content\": system_message },\n",
    "    { \"role\": \"user\", \"content\": prompt }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
